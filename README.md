# PODâ€‘iLQRâ€‘python ðŸ“ˆâš™ï¸  
*Informationâ€‘state modelâ€‘based RL for nonlinear PDE control*

[![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)](https://www.python.org/)  

This repo contains a **Python implementation of PODâ€‘iLQR (PODÂ²C)**â€”an informationâ€‘state extension of modelâ€‘based reinforcement learning extended to highâ€‘dimensional PDE systems.

> **Reference paper:**  
> *â€œAn Informationâ€‘State Based Approach to Linear Timeâ€‘Varying System Identification and Controlâ€*  
> [[arXiv 2211.10583](https://arxiv.org/pdf/2211.10583)]

---

## ðŸš€ Key ideas
* **Informationâ€‘state dynamics**: latent dynamics updated online using measurement residuals.
* **ARMA-LTV system identification**: The original state-space is recovered by stacking past information state and control inputs to fit a linear, time-varying ARMA model.  
* **iLQR in the loop**: trajectory optimization in the reduced space drives realâ€‘time control.  

---

## ðŸ—ï¸ Applications included

| PDE / System | State Dim. | Observations | Control Inputs |
|--------------|-----------:|-------------:|---------------:|
| **1â€‘D viscous Burgers** | 100 | 3 probes | 2 (endâ€‘wall suction / blowing) |
| **Allenâ€‘Cahn** (microâ€‘structure phase separation) | 2â€¯500 | 5 probes | 4 control inputs |
| **Cahnâ€‘Hilliard** (microâ€‘structure phase separation) | 400 | 5 probes | 4 control inputs |

> For scripts, see `burgers_model_free_ddp.py`, `material_model_free_ddp.py`.

---

## ðŸ“¦ Installation

```bash
git clone https://github.com/AayushmanSharma96/POD-ILQR-python.git
cd POD-ILQR-python


